# Make sure you dont add single or double quotes in the variable values, example : 
# correct format is : LLM_BASE_URL=http://localhost:1234/v1
# but incorrect format is : LLM_BASE_URL="http://localhost:1234/v1"

LLM_BASE_URL=<your model provider base url ex. for openai it is https://api.openai.com/v1/ or for LM Studio it is http://localhost:1234/v1>
LLM_API_KEY=<your model provider api key, ex. for lm-studio lm-studio>
LLM_MODEL_NAME=<your model name ex. qwen3-14b>
#TTS URL
TTS_BASE_URL=http://localhost:8880/v1
TTS_API_KEY=special-key
#whether to disable thinking mode in LLMs like Qwen3, R1 etc for faster inference. Takes in values of either true or false. Default is true>
NO_THINK_MODE=true
#Choose the value based on this guide: https://github.com/getfit-us/audiobook-creator-v2/?tab=readme-ov-file#parallel-batch-inferencing-of-audio-for-faster-audio-generation
MAX_PARALLEL_REQUESTS_BATCH_SIZE=2
#If using kokoro keep default / switch to orpheus for Oprheus TTS
TTS_MODEL=kokoro 
# Optional: To enable the Kokoro FastAPI service for TTS, run docker-compose with the 'kokoro' profile:
# docker-compose --profile kokoro up